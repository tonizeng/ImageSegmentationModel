{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cef0e2-3e31-40bd-8d6b-fabbcacda091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import platform\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"NVIDIA/CUDA GPU is\", \"available\" if has_gpu else \"NOT AVAILABLE\")\n",
    "print(\"MPS (Apple Metal) is\", \"AVAILABLE\" if has_mps else \"NOT AVAILABLE\")\n",
    "print(f\"Target device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199a0e9-4a99-4146-b4c3-ca2cf9408cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b02f6-5a53-4715-a65f-05420de399a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af518f1f-13e3-43bc-a526-5c4ed186cf82",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27d681-8888-4e7c-b28c-295da1f0f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img_path, threshold):\n",
    "    \"\"\"\n",
    "    Obtains predictions from the model for an image at the given path.\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    img_tensor = transform(img)\n",
    "    with torch.no_grad():\n",
    "        pred = model([img_tensor])\n",
    "    pred_score = list(pred[0]['scores'].detach().numpy())\n",
    "    pred_t = [pred_score.index(x) for x in pred_score if x > threshold]\n",
    "    if pred_t:\n",
    "        pred_t = pred_t[-1]\n",
    "    else:\n",
    "        pred_t = 0  \n",
    "    masks = (pred[0]['masks'] > 0.5).squeeze().detach().cpu().numpy()\n",
    "    pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())]\n",
    "    pred_boxes = [[(int(i[0]), int(i[1])), (int(i[2]), int(i[3]))] for i in list(pred[0]['boxes'].detach().numpy())]\n",
    "    masks = masks[:pred_t+1]\n",
    "    pred_boxes = pred_boxes[:pred_t+1]\n",
    "    pred_class = pred_class[:pred_t+1]\n",
    "    return masks, pred_boxes, pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090200c-d023-43b5-b88b-1718eadef2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_mask(img_path, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Blurs the 'person' masks in an image.\n",
    "    \"\"\"\n",
    "    person_detected = False\n",
    "    no_detection = \"\"\n",
    "    \n",
    "    masks, boxes, pred_cls = get_prediction(img_path, threshold)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    for i in range(len(masks)):\n",
    "        if pred_cls[i] == 'person':  \n",
    "            person_detected = True\n",
    "            mask = masks[i]\n",
    "            blurred = cv2.GaussianBlur(img, (41, 41), 30)  # apply Gaussian blur to the entire image\n",
    "            img[mask == 1] = blurred[mask == 1]  # apply the blurred area only to the mask\n",
    "            \n",
    "    if not person_detected:\n",
    "        print(\"No persons detected in the image.\")\n",
    "        print(\"Image Path is: \" + img_path)\n",
    "        no_detection = img_path\n",
    "        return None, no_detection\n",
    "        \n",
    "    height, width, _ = img.shape\n",
    "    plt.figure(figsize=(width / 100, height / 100))  \n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  \n",
    "    plt.show()\n",
    "\n",
    "    return img, no_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79795a4e-1677-4822-930b-eea845dd2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Blurs the 'person' masks in an image and saves the processed photo to the output folder.\n",
    "    \"\"\"\n",
    "    unprocessed_images = []\n",
    "\n",
    "    # create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # iterate through all folders and subfolders in the input directory\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if 'rgb' in file:  # process only files with 'rgb' in their name\n",
    "                img_path = os.path.join(root, file)\n",
    "                output_subdir = os.path.join(output_dir, os.path.relpath(root, input_dir))\n",
    "                output_img_path = os.path.join(output_subdir, file)\n",
    "\n",
    "                # Check if the output image path already exists\n",
    "                if os.path.exists(output_img_path):\n",
    "                    print(f\"{output_img_path} already exists, skipping processing.\")\n",
    "                    continue\n",
    "\n",
    "                # create output subdirectory if it doesn't exist\n",
    "                if not os.path.exists(output_subdir):\n",
    "                    os.makedirs(output_subdir)\n",
    "\n",
    "                # process the image\n",
    "                processed_img, no_detection = blur_mask(img_path, threshold=0.3)\n",
    "                print(output_img_path)\n",
    "\n",
    "                if no_detection:\n",
    "                    unprocessed_images.append(img_path)  # Append the image path instead of the flag\n",
    "\n",
    "                # ensure processed_img is not None and is a valid image, or use the original image if processing failed\n",
    "                if processed_img is not None and len(processed_img.shape) == 3:\n",
    "                    pil_img = Image.fromarray(processed_img)\n",
    "                else:\n",
    "                    pil_img = Image.open(img_path)\n",
    "                    print(f\"No detection in {img_path}. Saving the original image.\")\n",
    "\n",
    "                # save the image (processed or original) to output path\n",
    "                pil_img.save(output_img_path)\n",
    "\n",
    "            if 'bounding_boxes' in file:  # adds bounding box files\n",
    "                txt_input_path = os.path.join(root, file)\n",
    "                txt_output_path = os.path.join(output_subdir, file)\n",
    "\n",
    "                # Check if the bounding box file already exists\n",
    "                if os.path.exists(txt_output_path):\n",
    "                    print(f\"{txt_output_path} already exists, skipping copy.\")\n",
    "                    continue\n",
    "\n",
    "                # copy the txt file to the output directory\n",
    "                shutil.copy(txt_input_path, txt_output_path)\n",
    "                print(f\"Uploaded {txt_output_path} successfully.\")\n",
    "\n",
    "    for path in unprocessed_images:\n",
    "        print(f\"No persons detected in image: {path}\")\n",
    "\n",
    "    print(f\"There are {len(unprocessed_images)} images that were not processed successfully.\")\n",
    "\n",
    "    return unprocessed_images  # Return the list of unprocessed images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7292d940-ec2d-4df2-bd93-c50d18c19e44",
   "metadata": {},
   "source": [
    "## BATCH PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55cb9c-1401-4e6d-b582-fe31edce5093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 1 - learned objects\n",
    "input_dir = 'learned_objects_input1/'\n",
    "output_dir = 'learned_objects'\n",
    "process_images(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ea81d-fb40-41ac-9424-28228401c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 2 - learned objects\n",
    "input_dir = 'learned_objects_input2/'\n",
    "output_dir = 'learned_objects'\n",
    "process_images(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df6b21-6e4c-4501-ac7c-2bb14e640ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 3 - learned objects\n",
    "input_dir = 'learned_objects_input3/'\n",
    "output_dir = 'learned_objects'\n",
    "process_images(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab400c-c69a-4466-8eba-0fcba045a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 1 - test objects\n",
    "input_dir = 'test_objects_input/'\n",
    "output_dir = 'test_objects'\n",
    "process_images(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b3c87-3864-4b92-b17f-5e2d4bd8111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 2 - test objects\n",
    "input_dir = 'test_objects_input2/'\n",
    "output_dir = 'test_objects'\n",
    "process_images(input_dir, output_dir);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
